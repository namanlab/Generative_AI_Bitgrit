{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06545535-5e28-433d-bc4d-4f58cd0f4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Dense, LeakyReLU\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "DATASET_PATH = \"Dataset/\"\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19452078-977b-4ab1-9283-24fbcde596bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "    \n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fc80e99-25ce-4fa7-8606-f62e60e2b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATASET_PATH + \"train.csv\")\n",
    "test_df = pd.read_csv(DATASET_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f080ef2-2afe-41fd-9bea-b7ac3eecdf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.388242</td>\n",
       "      <td>0.868285</td>\n",
       "      <td>-0.427619</td>\n",
       "      <td>-0.678964</td>\n",
       "      <td>-1.625735</td>\n",
       "      <td>0.262761</td>\n",
       "      <td>1.243040</td>\n",
       "      <td>1.537751</td>\n",
       "      <td>-0.352028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776403</td>\n",
       "      <td>-0.662884</td>\n",
       "      <td>-0.257091</td>\n",
       "      <td>-1.168413</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>-0.482520</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>-0.382265</td>\n",
       "      <td>-0.539349</td>\n",
       "      <td>-1.682404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.496920</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.989040</td>\n",
       "      <td>0.451422</td>\n",
       "      <td>0.513516</td>\n",
       "      <td>-0.099658</td>\n",
       "      <td>-1.124326</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>-0.216224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379635</td>\n",
       "      <td>-1.760084</td>\n",
       "      <td>1.125450</td>\n",
       "      <td>-0.328047</td>\n",
       "      <td>-0.880305</td>\n",
       "      <td>-1.257607</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>2.021104</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>-0.423029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.128369</td>\n",
       "      <td>-0.537951</td>\n",
       "      <td>2.544358</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.904994</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>-0.495768</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>-1.418468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.373589</td>\n",
       "      <td>-0.483701</td>\n",
       "      <td>-0.964782</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>-0.444567</td>\n",
       "      <td>-0.531935</td>\n",
       "      <td>-0.878660</td>\n",
       "      <td>1.099488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>1.746814</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>1.844524</td>\n",
       "      <td>-0.327977</td>\n",
       "      <td>1.226839</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>0.379008</td>\n",
       "      <td>-1.003667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442288</td>\n",
       "      <td>-2.794472</td>\n",
       "      <td>-0.763468</td>\n",
       "      <td>-0.789832</td>\n",
       "      <td>-0.113209</td>\n",
       "      <td>-2.703150</td>\n",
       "      <td>-2.058728</td>\n",
       "      <td>1.070627</td>\n",
       "      <td>-0.458045</td>\n",
       "      <td>-0.435825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.423209</td>\n",
       "      <td>-0.983594</td>\n",
       "      <td>-1.694170</td>\n",
       "      <td>1.197507</td>\n",
       "      <td>1.044211</td>\n",
       "      <td>0.518777</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>-0.365174</td>\n",
       "      <td>0.738447</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.624450</td>\n",
       "      <td>-3.200223</td>\n",
       "      <td>0.711422</td>\n",
       "      <td>-0.190394</td>\n",
       "      <td>0.337224</td>\n",
       "      <td>-1.656639</td>\n",
       "      <td>0.707360</td>\n",
       "      <td>-0.562290</td>\n",
       "      <td>1.471181</td>\n",
       "      <td>-0.192000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0   1 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040   \n",
       "1   2 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
       "2   3  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
       "3   4  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
       "4   5  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
       "\n",
       "        f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193    f_1194  \\\n",
       "0  1.537751 -0.352028  ... -0.776403 -0.662884 -0.257091 -1.168413  0.223260   \n",
       "1  0.729430 -0.216224  ...  0.379635 -1.760084  1.125450 -0.328047 -0.880305   \n",
       "2  0.060111 -1.418468  ...  1.165254 -1.373589 -0.483701 -0.964782 -0.869555   \n",
       "3  0.379008 -1.003667  ... -0.442288 -2.794472 -0.763468 -0.789832 -0.113209   \n",
       "4 -0.365174  0.738447  ... -2.624450 -3.200223  0.711422 -0.190394  0.337224   \n",
       "\n",
       "     f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
       "1 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
       "2  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
       "3 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
       "4 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6299fdf-bab2-4879-b77c-59edffd00e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "X = train_df.iloc[:, 1:] \n",
    "y = train_df.iloc[:, 0]  \n",
    "X, y = X.values, y.values\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data into the required format (assuming images are 20x20x3)\n",
    "X = X.reshape(-1, 20, 20, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cc2588-ca64-4547-8695-523a55742752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.8025 - f1_m: 0.3447\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.4891 - f1_m: 0.4188\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.4175 - f1_m: 0.5058\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.3599 - f1_m: 0.6134\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.3150 - f1_m: 0.6895\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.3361 - f1_m: 0.6623\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.2679 - f1_m: 0.7474\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.2011 - f1_m: 0.8260\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.1564 - f1_m: 0.8704\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.1219 - f1_m: 0.9024\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0868 - f1_m: 0.9403\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0611 - f1_m: 0.9514\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0760 - f1_m: 0.9478\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0539 - f1_m: 0.9643\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0431 - f1_m: 0.9647\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0406 - f1_m: 0.9734\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0490 - f1_m: 0.9592\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0417 - f1_m: 0.9668\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0477 - f1_m: 0.9599\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0176 - f1_m: 0.9840\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0341 - f1_m: 0.9737\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0419 - f1_m: 0.9736\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0139 - f1_m: 0.9836\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0091 - f1_m: 0.9896\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0405 - f1_m: 0.9774\n",
      "Epoch 26/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.1313 - f1_m: 0.8954\n",
      "Epoch 27/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0421 - f1_m: 0.9676\n",
      "Epoch 28/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0203 - f1_m: 0.9807\n",
      "Epoch 29/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0066 - f1_m: 0.9963\n",
      "Epoch 30/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0050 - f1_m: 0.9920\n",
      "Epoch 31/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0107 - f1_m: 0.9881\n",
      "Epoch 32/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0458 - f1_m: 0.9641\n",
      "Epoch 33/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0304 - f1_m: 0.9811\n",
      "Epoch 34/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0133 - f1_m: 0.9842\n",
      "Epoch 35/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0088 - f1_m: 0.9942\n",
      "Epoch 36/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0223 - f1_m: 0.9792\n",
      "Epoch 37/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0246 - f1_m: 0.9778\n",
      "Epoch 38/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0084 - f1_m: 0.9955\n",
      "Epoch 39/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0014 - f1_m: 0.9937\n",
      "Epoch 40/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 5.8014e-04 - f1_m: 0.9939\n",
      "Epoch 41/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 3.4898e-04 - f1_m: 0.9939\n",
      "Epoch 42/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 6.4781e-04 - f1_m: 0.9936\n",
      "Epoch 43/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0128 - f1_m: 0.9927\n",
      "Epoch 44/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0651 - f1_m: 0.9466\n",
      "Epoch 45/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0155 - f1_m: 0.9899\n",
      "Epoch 46/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0427 - f1_m: 0.9641\n",
      "Epoch 47/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0264 - f1_m: 0.9771\n",
      "Epoch 48/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0105 - f1_m: 0.9885\n",
      "Epoch 49/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0119 - f1_m: 0.9938\n",
      "Epoch 50/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0922 - f1_m: 0.9450\n",
      "Epoch 51/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0171 - f1_m: 0.9904\n",
      "Epoch 52/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0060 - f1_m: 0.9904\n",
      "Epoch 53/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0033 - f1_m: 0.9978\n",
      "Epoch 54/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0019 - f1_m: 0.9997\n",
      "Epoch 55/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0081 - f1_m: 0.9896\n",
      "Epoch 56/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0170 - f1_m: 0.9744\n",
      "Epoch 57/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0075 - f1_m: 0.9886\n",
      "Epoch 58/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0028 - f1_m: 0.9927\n",
      "Epoch 59/100\n",
      "165/165 [==============================] - 1s 9ms/step - loss: 0.0083 - f1_m: 0.9887\n",
      "Epoch 60/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0272 - f1_m: 0.9792\n",
      "Epoch 61/100\n",
      "165/165 [==============================] - 1s 9ms/step - loss: 0.0147 - f1_m: 0.9823\n",
      "Epoch 62/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0149 - f1_m: 0.9861\n",
      "Epoch 63/100\n",
      "165/165 [==============================] - 1s 9ms/step - loss: 0.0265 - f1_m: 0.9835\n",
      "Epoch 64/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0086 - f1_m: 0.9946\n",
      "Epoch 65/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0018 - f1_m: 0.9993\n",
      "Epoch 66/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0013 - f1_m: 0.9993\n",
      "Epoch 67/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0069 - f1_m: 0.9945\n",
      "Epoch 68/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0411 - f1_m: 0.9672\n",
      "Epoch 69/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0140 - f1_m: 0.9862\n",
      "Epoch 70/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0040 - f1_m: 0.9918\n",
      "Epoch 71/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0024 - f1_m: 0.9921\n",
      "Epoch 72/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0050 - f1_m: 0.9958\n",
      "Epoch 73/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0170 - f1_m: 0.9863\n",
      "Epoch 74/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0296 - f1_m: 0.9773\n",
      "Epoch 75/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0101 - f1_m: 0.9942\n",
      "Epoch 76/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0110 - f1_m: 0.9935\n",
      "Epoch 77/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0837 - f1_m: 0.9435\n",
      "Epoch 78/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0106 - f1_m: 0.9894\n",
      "Epoch 79/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0017 - f1_m: 0.9939\n",
      "Epoch 80/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 9.0623e-04 - f1_m: 0.9997\n",
      "Epoch 81/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 4.5570e-04 - f1_m: 0.9939\n",
      "Epoch 82/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 5.4021e-04 - f1_m: 0.9935\n",
      "Epoch 83/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 2.6489e-04 - f1_m: 1.0000\n",
      "Epoch 84/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 2.5952e-04 - f1_m: 1.0000\n",
      "Epoch 85/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 1.7203e-04 - f1_m: 1.0000\n",
      "Epoch 86/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 2.1723e-04 - f1_m: 1.0000\n",
      "Epoch 87/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0025 - f1_m: 0.9939\n",
      "Epoch 88/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0995 - f1_m: 0.9405\n",
      "Epoch 89/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0288 - f1_m: 0.9748\n",
      "Epoch 90/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0068 - f1_m: 0.9910\n",
      "Epoch 91/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0045 - f1_m: 0.9979\n",
      "Epoch 92/100\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0071 - f1_m: 0.9896\n",
      "Epoch 93/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0076 - f1_m: 0.9886\n",
      "Epoch 94/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0435 - f1_m: 0.9736\n",
      "Epoch 95/100\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.0112 - f1_m: 0.9938\n",
      "Epoch 96/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0073 - f1_m: 0.9907\n",
      "Epoch 97/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0019 - f1_m: 0.9994\n",
      "Epoch 98/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0021 - f1_m: 0.9989\n",
      "Epoch 99/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0018 - f1_m: 0.9987\n",
      "Epoch 100/100\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 0.0015 - f1_m: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2af58e790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "def create_model():\n",
    "    x = Input(shape=(20, 20, 3))\n",
    "    x1 = Conv2D(16, (3, 3), padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding='same', activation='relu')(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "    x3 = Conv2D(32, (5, 5), padding='same', activation='relu')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "    x4 = Conv2D(64, (5, 5), padding='same', activation='relu')(x3)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "    y = Flatten()(x4)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(32)(y)\n",
    "    y = LeakyReLU(alpha=0.1)(y)\n",
    "    y = Dense(16)(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(1, activation='sigmoid')(y)\n",
    "    return tf.keras.Model(inputs=x, outputs=y)\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1_m])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be32f50f-fcab-4c48-8a4e-a3c63d93c89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_df_new = test_df.iloc[:, 1:].values\n",
    "test_df_new = test_df_new.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data into the required format (assuming images are 20x20x3)\n",
    "test_df_new = test_df_new.reshape(-1, 20, 20, 3)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_pred_proba = model.predict(test_df_new)\n",
    "y_pred = np.where(y_pred_proba > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7c07841-65a7-42c1-9118-49086730f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = test_df.iloc[:, 0].values\n",
    "prediction = pd.DataFrame({'id': indices, 'labels': y_pred.flatten()}).to_csv('sub_1.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
